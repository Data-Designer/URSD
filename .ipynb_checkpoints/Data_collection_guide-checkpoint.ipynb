{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide for downloading Multi-Model Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token information  \n",
    "\n",
    "Here, we used Autorized token given by https://developers.arcgis.com/dashboard  \n",
    "Please make ArcGIS developers account. It's free!\n",
    "\n",
    "## Multi-Model Data\n",
    "\n",
    "There are six codes to run for downloading all data: ```metadata.py```, ```asset.py```, ```daytime_image.py```,```night_light.py```,```night_eval.py```,```road_network.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata collection  \n",
    "\n",
    "```metadata.py``` \n",
    "+ input\n",
    "    * necessary \n",
    "        - zoom level (--zl)\n",
    "        - nation (--nation)\n",
    "        - minor (--minor)\n",
    "        - data set (--dset)\n",
    "        - data collection name (--dcoll)\n",
    "        - Autorized token (--token)\n",
    "    * necessary, naming variables\n",
    "        - name of output \\[z,y,x\\] for each district, saved as .json (--ozyx)\n",
    "        - name of output demographic data referring data set and data collection, saved as .csv (--dset)\n",
    "    * optional\n",
    "        - start, end points when you want to split the job (--start, --end respectively)  \n",
    "        \n",
    "+ output\n",
    "    * Country geometry file, saved as .shp\n",
    "    * \\[z,y,x\\] for each district, saved as .json\n",
    "    * Demographic data referring data set and data collection, saved as .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes  \n",
    "\n",
    "For *nation*, you can check the nation code of each country at  \n",
    "https://developers.arcgis.com/rest/geoenrichment/api-reference/geoenrichment-coverage.htm  \n",
    "\n",
    "For *minor*, *dset*, *dcoll*, you can check the inputs from  \n",
    "https://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/Geoenrichment/Countries\n",
    "\n",
    "You can even observe specific country that you selected. In case of South Korea, nation code is __KOR__. The URL  \n",
    "https://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/Geoenrichment/Countries/KOR?f=pjson  \n",
    "returns information at South Korea\n",
    "\n",
    "#### code example  \n",
    "With zoom level 15:  \n",
    "```python metadata.py --zl 15 --ozyx ozyx_ch_district_z15 --odat odat_ch_district_z15 --token ***\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asset download\n",
    "\n",
    "```asset.py```\n",
    "\n",
    "Before run the code, go to https://export.hotosm.org/en/v3/ for country level asset\n",
    "\n",
    "Clicking the **create** button, import geojson file from **data/json** folder, name as *asset*, choose *shapefile* format, data yaml copy from **data/asset/asset.yml**, repeat util all province are downloaded\n",
    "\n",
    "While country level asset has been downloaded, run ```asset.py``` for processed grid level asset and processed county level asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```asset.py```  \n",
    "+ input\n",
    "    * necessary\n",
    "        - ozyx .json file path from metadata_collection.py (--zyx)\n",
    "        - odat .csv file path from metadata_collection.py (--dat)\n",
    "    * necessary, naming variables\n",
    "        - directory name to save whole images (--odir)\n",
    "        \n",
    "+ output\n",
    "    * Grid level asset saved as odir/{area_exposure_data.csv}\n",
    "    * County level asset saved as odir/{country_level_exposure_data.csv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### road network download\n",
    "\n",
    "```road_network.py```\n",
    "\n",
    "Same as asset download, before run the code, go to https://export.hotosm.org/en/v3/ for country level road_network\n",
    "\n",
    "Clicking the **create** button, import geojson file from **data/json** folder, name as *road_network*, choose *shapefile* format, data yaml copy from **data/road_network/road_network.yml**, repeat util all province are downloaded\n",
    "\n",
    "While country level road_network has been downloaded, run ```road_network.py``` for processed grid level road_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```road_network.py```  \n",
    "+ input\n",
    "    * necessary\n",
    "        - ozyx .json file path from metadata_collection.py (--zyx)\n",
    "        - odat .csv file path from metadata_collection.py (--dat)\n",
    "    * necessary, naming variables\n",
    "        - directory name to save whole images (--odir)\n",
    "        \n",
    "+ output\n",
    "    * Grid level road_network saved as odir/{area_road_network.csv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daytime image download  \n",
    "\n",
    "```daytime_image.py```\n",
    "\n",
    "Use multi-progress for quicker, which needed manual adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```daytime_image.py```  \n",
    "+ input\n",
    "    * necessary\n",
    "        - zoom level (--zl)\n",
    "        - Autorized token (--token)\n",
    "    * necessary, naming variables\n",
    "        - directory name to save whole images (--odir)\n",
    "        \n",
    "+ output\n",
    "    * Images saved as ... odir/{area}/{y_x.png}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nighttime image download  \n",
    "\n",
    "The code ```night_light.py``` downloads the nighttime imagery with maximum zoom level 9, and crop it with the size of daytime imagery. So it requires daytime imagery file path as one of the inputs. For an intermediate step, this also returns the original nightlight images that are not cropped.\n",
    "\n",
    "```night_light.py```   \n",
    "+ input\n",
    "    * necessary\n",
    "        - daytime satellite imagery directory path (--ddir)\n",
    "        - zoom level (usually 9)(--zl)\n",
    "        - zoom level difference between nightime and daytime. Ex) 15-9 = 6(--zdiff)\n",
    "        - nation code (--nation)\n",
    "    * necessary, naming variables\n",
    "        - directory name for original nightlight images (--ondir)\n",
    "        - directory name for cropped nightlight images (--cndir)\n",
    "        \n",
    "+ output\n",
    "    * Images saved as ondir/{y_x.png} (Nighttime sat images)\n",
    "    * images saved as cndir/{area}/{y_x.png} (Cropped nighttime sat images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nightlight image data evaluation\n",
    "\n",
    "The code ```night_eval.py``` get input of nightlight imageries with directory path,  \n",
    "where the imageries are saved as {nightlight_dir}/{area}/{y_x.png}  \n",
    "The code evaluate each nightlight image by taking pixel value as grayscale, and aggregate them as one value per each y_x.png image\n",
    "\n",
    "\n",
    "```night_eval.py ```\n",
    "+ input\n",
    "    * necessary\n",
    "        - target nightlight imagery directory(--tdir)\n",
    "        - Facebook population density csv file path (--odir)\n",
    "        - ouput csv file name (--ocsv)\n",
    "        \n",
    "+ output\n",
    "    * aggregated nightlight density per each y_x.png images, as {ocsv}.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match all data and generate train data\n",
    "\n",
    "The code ```train_data_process.py``` match all data and generate train data, run directly\n",
    "\n",
    "```train_data_process.py ```\n",
    "\n",
    "+ output\n",
    "    * used_data.csv used to train grid level model\n",
    "    * all_data_add_country.csv used to train county level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
